{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing TensorFlow (original) and PyTorch models\n",
    "\n",
    "You can use this small notebook to check the conversion of the model's weights from the TensorFlow model to the PyTorch model. In the following, we compare the weights of the last layer on a simple example (in `input.txt`) but both models returns all the hidden layers so you can check every stage of the model.\n",
    "\n",
    "To run this notebook, follow these instructions:\n",
    "- make sure that your Python environment has both TensorFlow and PyTorch installed,\n",
    "- download the original TensorFlow implementation,\n",
    "- download a pre-trained TensorFlow model as indicaded in the TensorFlow implementation readme,\n",
    "- run the script `convert_tf_checkpoint_to_pytorch.py` as indicated in the `README` to convert the pre-trained TensorFlow model to PyTorch.\n",
    "\n",
    "If needed change the relative paths indicated in this notebook (at the beggining of Sections 1 and 2) to point to the relevent models and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:56:48.412622Z",
     "start_time": "2018-11-15T14:56:48.400110Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0628 22:47:49.683971 139974244267776 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/ TensorFlow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:56:49.483829Z",
     "start_time": "2018-11-15T14:56:49.471296Z"
    }
   },
   "outputs": [],
   "source": [
    "original_tf_inplem_dir = \"../bert/\"\n",
    "model_dir = \"/tmp/pretraining_output/\"\n",
    "\n",
    "vocab_file = model_dir + \"vocab.txt\"\n",
    "bert_config_file = model_dir + \"bert_config.json\"\n",
    "init_checkpoint = model_dir + \"model.ckpt-20\"\n",
    "\n",
    "input_file = \"./samples/input.txt\"\n",
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:57:51.597932Z",
     "start_time": "2018-11-15T14:57:51.549466Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modeling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-370980322c9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec_from_file_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_tf_inplem_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/extract_features.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extract_features_tensorflow'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../bert'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch0/zjian/bert-pretraining/src/bert-pretraining/third_party/bert/extract_features.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modeling'"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "spec = importlib.util.spec_from_file_location('*', original_tf_inplem_dir + '/extract_features.py')\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)\n",
    "sys.modules['extract_features_tensorflow'] = module\n",
    "sys.path.append('../bert')\n",
    "from extract_features_tensorflow import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:58:05.650987Z",
     "start_time": "2018-11-15T14:58:05.541620Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 11:10:21.640357 140112437987072 deprecation_wrapper.py:119] From ../bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0628 11:10:21.792764 140112437987072 deprecation_wrapper.py:119] From ../bert//extract_features.py:297: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with tf.variable_scope(\"test\", dtype=tf.float64):\n",
    "layer_indexes = list(range(12))\n",
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file=vocab_file, do_lower_case=True)\n",
    "examples = read_examples(input_file)\n",
    "\n",
    "features = convert_examples_to_features(\n",
    "    examples=examples, seq_length=max_seq_length, tokenizer=tokenizer)\n",
    "unique_id_to_feature = {}\n",
    "for feature in features:\n",
    "    unique_id_to_feature[feature.unique_id] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:58:11.562443Z",
     "start_time": "2018-11-15T14:58:08.036485Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 11:10:23.922789 140112437987072 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0628 11:10:23.925731 140112437987072 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6e40398b70>) includes params argument, but params are not passed to Estimator.\n",
      "W0628 11:10:23.930257 140112437987072 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpalg_r0p1\n",
      "W0628 11:10:23.933089 140112437987072 tpu_context.py:750] Setting TPUConfig.num_shards==1 is an unsupported behavior. Please fix as soon as possible (leaving num_shards as None.)\n",
      "W0628 11:10:23.934185 140112437987072 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "# with tf.variable_scope(\"test\", dtype=tf.float64):\n",
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    master=None,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        num_shards=1,\n",
    "        per_host_input_for_training=is_per_host))\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    init_checkpoint=init_checkpoint,\n",
    "    layer_indexes=layer_indexes,\n",
    "    use_tpu=False,\n",
    "    use_one_hot_embeddings=False)\n",
    "\n",
    "# If TPU is not available, this will fall back to normal Estimator on CPU\n",
    "# or GPU.\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=False,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    predict_batch_size=1)\n",
    "\n",
    "input_fn = input_fn_builder(\n",
    "    features=features, seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:58:21.736543Z",
     "start_time": "2018-11-15T14:58:16.723829Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 11:10:24.777451 140112437987072 deprecation_wrapper.py:119] From ../bert//extract_features.py:162: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0628 11:10:24.785151 140112437987072 deprecation_wrapper.py:119] From ../bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0628 11:10:24.818706 140112437987072 deprecation.py:323] From ../bert/modeling.py:485: to_double (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0628 11:10:24.825600 140112437987072 deprecation_wrapper.py:119] From ../bert/modeling.py:495: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "W0628 11:10:24.893762 140112437987072 deprecation.py:323] From ../bert/modeling.py:676: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double check  Tensor(\"bert/embeddings/ToDouble:0\", shape=(?, 2), dtype=float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 11:10:27.659510 140112437987072 deprecation_wrapper.py:119] From ../bert//extract_features.py:174: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0628 11:10:27.670760 140112437987072 deprecation_wrapper.py:119] From ../bert//extract_features.py:187: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W0628 11:10:28.989188 140112437987072 deprecation.py:323] From /lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'bert/embeddings/word_embeddings:0' shape=(30522, 768) dtype=float64_ref>, <tf.Variable 'bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float64_ref>, <tf.Variable 'bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float64_ref>, <tf.Variable 'bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float64_ref>, <tf.Variable 'bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float64_ref>, <tf.Variable 'bert/pooler/dense/bias:0' shape=(768,) dtype=float64_ref>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0628 11:10:30.636290 140112437987072 error_handling.py:70] Error recorded from prediction_loop: tensor_name = bert/encoder/layer_7/attention/self/value/kernel; expected dtype double does not equal original dtype float\n",
      "\t [[node checkpoint_initializer_158 (defined at ../bert//extract_features.py:187) ]]\n",
      "\n",
      "Original stack trace for 'checkpoint_initializer_158':\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n",
      "    self.run()\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-4dd15cdb6ee2>\", line 3, in <module>\n",
      "    for result in estimator.predict(input_fn, yield_single_examples=True):\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2913, in predict\n",
      "    yield_single_examples=yield_single_examples):\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 619, in predict\n",
      "    features, None, ModeKeys.PREDICT, self.config)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2709, in _call_model_fn\n",
      "    config)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1146, in _call_model_fn\n",
      "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2967, in _model_fn\n",
      "    features, labels, is_export_mode=is_export_mode)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1549, in call_without_tpu\n",
      "    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1867, in _call_model_fn\n",
      "    estimator_spec = self._model_fn(features=features, **kwargs)\n",
      "  File \"../bert//extract_features.py\", line 187, in model_fn\n",
      "    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 291, in init_from_checkpoint\n",
      "    init_from_checkpoint_fn)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1684, in merge_call\n",
      "    return self._merge_call(merge_fn, args, kwargs)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1691, in _merge_call\n",
      "    return merge_fn(self._strategy, *args, **kwargs)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 286, in <lambda>\n",
      "    ckpt_dir_or_file, assignment_map)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 334, in _init_from_checkpoint\n",
      "    _set_variable_or_list_initializer(var, ckpt_file, tensor_name_in_ckpt)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 458, in _set_variable_or_list_initializer\n",
      "    _set_checkpoint_initializer(variable_or_list, ckpt_file, tensor_name, \"\")\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 412, in _set_checkpoint_initializer\n",
      "    ckpt_file, [tensor_name], [slice_spec], [base_type], name=name)[0]\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n",
      "    name=name)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 11:10:30.638432 140112437987072 error_handling.py:130] Reraising captured error\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "tensor_name = bert/encoder/layer_7/attention/self/value/kernel; expected dtype double does not equal original dtype float\n\t [[node checkpoint_initializer_158 (defined at ../bert//extract_features.py:187) ]]\n\nOriginal stack trace for 'checkpoint_initializer_158':\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-4dd15cdb6ee2>\", line 3, in <module>\n    for result in estimator.predict(input_fn, yield_single_examples=True):\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2913, in predict\n    yield_single_examples=yield_single_examples):\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 619, in predict\n    features, None, ModeKeys.PREDICT, self.config)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2709, in _call_model_fn\n    config)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1146, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2967, in _model_fn\n    features, labels, is_export_mode=is_export_mode)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1549, in call_without_tpu\n    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1867, in _call_model_fn\n    estimator_spec = self._model_fn(features=features, **kwargs)\n  File \"../bert//extract_features.py\", line 187, in model_fn\n    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 291, in init_from_checkpoint\n    init_from_checkpoint_fn)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1684, in merge_call\n    return self._merge_call(merge_fn, args, kwargs)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1691, in _merge_call\n    return merge_fn(self._strategy, *args, **kwargs)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 286, in <lambda>\n    ckpt_dir_or_file, assignment_map)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 334, in _init_from_checkpoint\n    _set_variable_or_list_initializer(var, ckpt_file, tensor_name_in_ckpt)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 458, in _set_variable_or_list_initializer\n    _set_checkpoint_initializer(variable_or_list, ckpt_file, tensor_name, \"\")\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 412, in _set_checkpoint_initializer\n    ckpt_file, [tensor_name], [slice_spec], [base_type], name=name)[0]\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: tensor_name = bert/encoder/layer_7/attention/self/value/kernel; expected dtype double does not equal original dtype float\n\t [[{{node checkpoint_initializer_158}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4dd15cdb6ee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# with tf.variable_scope(\"test\", dtype=tf.float64):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtensorflow_all_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myield_single_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0munique_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"unique_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_id_to_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munique_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m   2917\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2918\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2919\u001b[0;31m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m     \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reraising captured error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m   2911\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2913\u001b[0;31m           yield_single_examples=yield_single_examples):\n\u001b[0m\u001b[1;32m   2914\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mscaffold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaffold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 config=self._session_config),\n\u001b[0;32m--> 635\u001b[0;31m             hooks=all_hooks) as mon_sess:\n\u001b[0m\u001b[1;32m    636\u001b[0m           \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0mpreds_evaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    723\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \"\"\"\n\u001b[1;32m   1199\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         logging.info(\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    294\u001b[0m                            \"init_fn or local_init_op was given\")\n\u001b[1;32m    295\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0minit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: tensor_name = bert/encoder/layer_7/attention/self/value/kernel; expected dtype double does not equal original dtype float\n\t [[node checkpoint_initializer_158 (defined at ../bert//extract_features.py:187) ]]\n\nOriginal stack trace for 'checkpoint_initializer_158':\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-4dd15cdb6ee2>\", line 3, in <module>\n    for result in estimator.predict(input_fn, yield_single_examples=True):\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2913, in predict\n    yield_single_examples=yield_single_examples):\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 619, in predict\n    features, None, ModeKeys.PREDICT, self.config)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2709, in _call_model_fn\n    config)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1146, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 2967, in _model_fn\n    features, labels, is_export_mode=is_export_mode)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1549, in call_without_tpu\n    return self._call_model_fn(features, labels, is_export_mode=is_export_mode)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 1867, in _call_model_fn\n    estimator_spec = self._model_fn(features=features, **kwargs)\n  File \"../bert//extract_features.py\", line 187, in model_fn\n    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 291, in init_from_checkpoint\n    init_from_checkpoint_fn)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1684, in merge_call\n    return self._merge_call(merge_fn, args, kwargs)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1691, in _merge_call\n    return merge_fn(self._strategy, *args, **kwargs)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 286, in <lambda>\n    ckpt_dir_or_file, assignment_map)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 334, in _init_from_checkpoint\n    _set_variable_or_list_initializer(var, ckpt_file, tensor_name_in_ckpt)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 458, in _set_variable_or_list_initializer\n    _set_checkpoint_initializer(variable_or_list, ckpt_file, tensor_name, \"\")\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\", line 412, in _set_checkpoint_initializer\n    ckpt_file, [tensor_name], [slice_spec], [base_type], name=name)[0]\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/lfs/1/zjian/anaconda2/envs/bert-pretraining/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# with tf.variable_scope(\"test\", dtype=tf.float64):\n",
    "tensorflow_all_out = []\n",
    "for result in estimator.predict(input_fn, yield_single_examples=True):\n",
    "    unique_id = int(result[\"unique_id\"])\n",
    "    feature = unique_id_to_feature[unique_id]\n",
    "    output_json = collections.OrderedDict()\n",
    "    output_json[\"linex_index\"] = unique_id\n",
    "    tensorflow_all_out_features = []\n",
    "    # for (i, token) in enumerate(feature.tokens):\n",
    "    all_layers = []\n",
    "    for (j, layer_index) in enumerate(layer_indexes):\n",
    "        print(\"extracting layer {}\".format(j))\n",
    "        layer_output = result[\"layer_output_%d\" % j]\n",
    "        layers = collections.OrderedDict()\n",
    "        layers[\"index\"] = layer_index\n",
    "        layers[\"values\"] = layer_output\n",
    "        all_layers.append(layers)\n",
    "    tensorflow_out_features = collections.OrderedDict()\n",
    "    tensorflow_out_features[\"layers\"] = all_layers\n",
    "    tensorflow_all_out_features.append(tensorflow_out_features)\n",
    "\n",
    "    output_json[\"features\"] = tensorflow_all_out_features\n",
    "    tensorflow_all_out.append(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with sess as tf.session():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "print(tvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:58:23.970714Z",
     "start_time": "2018-11-15T14:58:23.931930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "odict_keys(['linex_index', 'features'])\n",
      "number of tokens 1\n",
      "number of layers 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(128, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tensorflow_all_out))\n",
    "print(len(tensorflow_all_out[0]))\n",
    "print(tensorflow_all_out[0].keys())\n",
    "print(\"number of tokens\", len(tensorflow_all_out[0]['features']))\n",
    "print(\"number of layers\", len(tensorflow_all_out[0]['features'][0]['layers']))\n",
    "tensorflow_all_out[0]['features'][0]['layers'][0]['values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T14:58:25.547012Z",
     "start_time": "2018-11-15T14:58:25.516076Z"
    }
   },
   "outputs": [],
   "source": [
    "tensorflow_outputs = list(tensorflow_all_out[0]['features'][0]['layers'][t]['values'] for t in layer_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.32029069  1.17394683 -0.26360368 ...  1.85500242 -1.81151755\n",
      "   1.21505852]\n",
      " [-1.36823489  0.71090095  0.44132799 ...  0.79780859 -1.56258003\n",
      "   0.10156749]\n",
      " [-1.35045821  1.10464981  0.45813221 ...  0.37352803 -0.58642476\n",
      "   1.81977958]\n",
      " ...\n",
      " [ 0.59371397  0.54279067  1.2337462  ...  1.43765635 -0.35358792\n",
      "   0.17982318]\n",
      " [ 0.05889777  0.53335308 -0.3478505  ...  0.16594686  0.8880447\n",
      "  -0.95944832]\n",
      " [-1.09464921 -0.2095373   1.7236201  ...  1.49718659 -0.1028087\n",
      "  -1.12150647]]\n"
     ]
    }
   ],
   "source": [
    "print(tensorflow_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[ 0.09768458  0.00179938 -0.14077505 ...  0.08461832  0.06095919\n",
    "  -0.00853015]\n",
    " [-0.00433884  0.6136221  -0.28382796 ...  0.0972865   0.099303\n",
    "  -0.7878085 ]\n",
    " [-0.32750753 -0.82382095  0.16448613 ... -0.19547357  0.1602732\n",
    "   0.09975615]\n",
    " ...\n",
    " [ 0.07915473 -0.3328963   0.61744314 ...  0.46285754 -0.32566088\n",
    "   0.02301384]\n",
    " [ 0.00915309 -0.38213047  0.48889852 ...  0.47541893 -0.24534532\n",
    "  -0.08870013]\n",
    " [ 0.14412603 -0.27417877  0.5007422  ...  0.763762   -0.5418124\n",
    "  -0.13567454]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/ PyTorch code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T15:03:49.528679Z",
     "start_time": "2018-11-15T15:03:49.497697Z"
    }
   },
   "outputs": [],
   "source": [
    "import extract_features\n",
    "import pytorch_pretrained_bert as ppb\n",
    "from extract_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T15:21:18.001177Z",
     "start_time": "2018-11-15T15:21:17.970369Z"
    }
   },
   "outputs": [],
   "source": [
    "init_checkpoint_pt = \"/tmp/pretraining_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T15:21:20.893669Z",
     "start_time": "2018-11-15T15:21:18.786623Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = ppb.BertModel.from_pretrained(init_checkpoint_pt)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T15:21:26.963427Z",
     "start_time": "2018-11-15T15:21:26.922494Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "all_input_type_ids = torch.tensor([f.input_type_ids for f in features], dtype=torch.long)\n",
    "all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
    "\n",
    "eval_data = TensorDataset(all_input_ids, all_input_mask, all_input_type_ids, all_example_index)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=1)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T15:21:30.718724Z",
     "start_time": "2018-11-15T15:21:30.329205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958, 27227,  2001,\n",
      "          1037, 13997, 11510,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([0])\n",
      "layer 0 0\n",
      "layer 1 1\n",
      "layer 2 2\n",
      "layer 3 3\n",
      "layer 4 4\n",
      "layer 5 5\n",
      "layer 6 6\n",
      "layer 7 7\n",
      "layer 8 8\n",
      "layer 9 9\n",
      "layer 10 10\n",
      "layer 11 11\n"
     ]
    }
   ],
   "source": [
    "layer_indexes = list(range(12))\n",
    "\n",
    "pytorch_all_out = []\n",
    "for input_ids, input_mask, input_type_ids, example_indices in eval_dataloader:\n",
    "    print(input_ids)\n",
    "    print(input_mask)\n",
    "    print(example_indices)\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "\n",
    "    all_encoder_layers, _ = model(input_ids, token_type_ids=input_type_ids, attention_mask=input_mask)\n",
    "\n",
    "    for b, example_index in enumerate(example_indices):\n",
    "        feature = features[example_index.item()]\n",
    "        unique_id = int(feature.unique_id)\n",
    "        # feature = unique_id_to_feature[unique_id]\n",
    "        output_json = collections.OrderedDict()\n",
    "        output_json[\"linex_index\"] = unique_id\n",
    "        all_out_features = []\n",
    "        # for (i, token) in enumerate(feature.tokens):\n",
    "        all_layers = []\n",
    "        for (j, layer_index) in enumerate(layer_indexes):\n",
    "            print(\"layer\", j, layer_index)\n",
    "            layer_output = all_encoder_layers[int(layer_index)].detach().cpu().numpy()\n",
    "            layer_output = layer_output[b]\n",
    "            layers = collections.OrderedDict()\n",
    "            layers[\"index\"] = layer_index\n",
    "            layer_output = layer_output\n",
    "            layers[\"values\"] = layer_output if not isinstance(layer_output, (int, float)) else [layer_output]\n",
    "            all_layers.append(layers)\n",
    "\n",
    "            out_features = collections.OrderedDict()\n",
    "            out_features[\"layers\"] = all_layers\n",
    "            all_out_features.append(out_features)\n",
    "        output_json[\"features\"] = all_out_features\n",
    "        pytorch_all_out.append(output_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T15:21:35.703615Z",
     "start_time": "2018-11-15T15:21:35.666150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "odict_keys(['linex_index', 'features'])\n",
      "number of tokens 1\n",
      "number of layers 12\n",
      "hidden_size 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(128, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(pytorch_all_out))\n",
    "print(len(pytorch_all_out[0]))\n",
    "print(pytorch_all_out[0].keys())\n",
    "print(\"number of tokens\", len(pytorch_all_out))\n",
    "print(\"number of layers\", len(pytorch_all_out[0]['features'][0]['layers']))\n",
    "print(\"hidden_size\", len(pytorch_all_out[0]['features'][0]['layers'][0]['values']))\n",
    "pytorch_all_out[0]['features'][0]['layers'][0]['values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T15:21:36.999073Z",
     "start_time": "2018-11-15T15:21:36.966762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 768)\n",
      "(128, 768)\n"
     ]
    }
   ],
   "source": [
    "pytorch_outputs = list(pytorch_all_out[0]['features'][0]['layers'][t]['values'] for t in layer_indexes)\n",
    "print(pytorch_outputs[0].shape)\n",
    "print(pytorch_outputs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T15:21:37.936522Z",
     "start_time": "2018-11-15T15:21:37.905269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 768)\n",
      "(128, 768)\n"
     ]
    }
   ],
   "source": [
    "print(tensorflow_outputs[0].shape)\n",
    "print(tensorflow_outputs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09768458  0.00179938 -0.14077505 ...  0.08461832  0.06095919\n",
      "  -0.00853015]\n",
      " [-0.00433884  0.6136221  -0.28382796 ...  0.0972865   0.099303\n",
      "  -0.7878085 ]\n",
      " [-0.32750753 -0.82382095  0.16448613 ... -0.19547357  0.1602732\n",
      "   0.09975615]\n",
      " ...\n",
      " [ 0.07915473 -0.3328963   0.61744314 ...  0.46285754 -0.32566088\n",
      "   0.02301384]\n",
      " [ 0.00915309 -0.38213047  0.48889852 ...  0.47541893 -0.24534532\n",
      "  -0.08870013]\n",
      " [ 0.14412603 -0.27417877  0.5007422  ...  0.763762   -0.5418124\n",
      "  -0.13567454]]\n"
     ]
    }
   ],
   "source": [
    "print(tensorflow_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[ 0.09768458  0.00179938 -0.14077505 ...  0.08461832  0.06095919\n",
    "  -0.00853015]\n",
    " [-0.00433884  0.6136221  -0.28382796 ...  0.0972865   0.099303\n",
    "  -0.7878085 ]\n",
    " [-0.32750753 -0.82382095  0.16448613 ... -0.19547357  0.1602732\n",
    "   0.09975615]\n",
    " ...\n",
    " [ 0.07915473 -0.3328963   0.61744314 ...  0.46285754 -0.32566088\n",
    "   0.02301384]\n",
    " [ 0.00915309 -0.38213047  0.48889852 ...  0.47541893 -0.24534532\n",
    "  -0.08870013]\n",
    " [ 0.14412603 -0.27417877  0.5007422  ...  0.763762   -0.5418124\n",
    "  -0.13567454]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09786137  0.00116818 -0.14105    ...  0.08469906  0.06104695\n",
      "  -0.00876771]\n",
      " [-0.00450904  0.6127007  -0.2837876  ...  0.09707876  0.09934989\n",
      "  -0.78852844]\n",
      " [-0.32704192 -0.82473737  0.16454487 ... -0.19533129  0.16034643\n",
      "   0.09961645]\n",
      " ...\n",
      " [ 0.07926201 -0.33316708  0.6171076  ...  0.4627899  -0.32563412\n",
      "   0.02256444]\n",
      " [ 0.00925751 -0.3823599   0.48858032 ...  0.47534108 -0.24534258\n",
      "  -0.08917644]\n",
      " [ 0.14433005 -0.27446604  0.5004202  ...  0.7637472  -0.5418068\n",
      "  -0.1361167 ]]\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3/ Comparing the standard deviation on the last layer of both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T15:21:39.437137Z",
     "start_time": "2018-11-15T15:21:39.406150Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T15:21:40.181870Z",
     "start_time": "2018-11-15T15:21:40.137023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape tensorflow layer, shape pytorch layer, standard deviation\n",
      "((128, 768), (128, 768), 0.00020616385)\n",
      "((128, 768), (128, 768), 0.0005438742)\n",
      "((128, 768), (128, 768), 0.00066474144)\n",
      "((128, 768), (128, 768), 0.0008685303)\n",
      "((128, 768), (128, 768), 0.0013178637)\n",
      "((128, 768), (128, 768), 0.001600817)\n",
      "((128, 768), (128, 768), 0.0021130955)\n",
      "((128, 768), (128, 768), 0.0023845905)\n",
      "((128, 768), (128, 768), 0.002587812)\n",
      "((128, 768), (128, 768), 0.00279683)\n",
      "((128, 768), (128, 768), 0.0029927932)\n",
      "((128, 768), (128, 768), 0.0014235352)\n"
     ]
    }
   ],
   "source": [
    "print('shape tensorflow layer, shape pytorch layer, standard deviation')\n",
    "print('\\n'.join(list(str((np.array(tensorflow_outputs[i]).shape,\n",
    "                          np.array(pytorch_outputs[i]).shape, \n",
    "                          np.sqrt(np.mean((np.array(tensorflow_outputs[i]) - np.array(pytorch_outputs[i]))**2.0)))) for i in range(12))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "bert-pretraining",
   "language": "python",
   "name": "bert-pretraining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
